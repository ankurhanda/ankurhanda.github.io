<!DOCTYPE html>
<html>
  <head>
    <title>Different DQN variations – Ankur Handa – writing my views on things I like</title>
  
        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="Over the years, different variations of the classic DQN have appeared each with their own attempt at reducing the amount of data needed to learn i.e. data efficiency and increasing the overall performance racked against humans at the ATARI benchmarks. These variations are listed below.

" />
    <meta property="og:description" content="Over the years, different variations of the classic DQN have appeared each with their own attempt at reducing the amount of data needed to learn i.e. data efficiency and increasing the overall performance racked against humans at the ATARI benchmarks. These variations are listed below.

" />
    
    <meta name="author" content="Ankur Handa" />

    
    <meta property="og:title" content="Different DQN variations" />
    <meta property="twitter:title" content="Different DQN variations" />
    

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Ankur Handa - writing my views on things I like" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
		TeX: {
		equationNumbers: {
		autoNumber: "AMS"
		}
		},
		tex2jax: {
		inlineMath: [ ['$','$'], ['\\(', '\\)'] ],
		displayMath: [ ['$$','$$'] ],
		processEscapes: true,
		processEnvironments: true,
		skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
		}
		});
    </script>

	<script type="text/x-mathjax-config">
	MathJax.Hub.Queue(function(){
		var all = MathJax.Hub.getAllJax(), i;
		for(i = 0; i < all.length; i += 1)
		{
		all[i].SourceElement().parentNode.className += ' has-jax';
		}
		});
	</script>

	<script type="text/javascript" async
	src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
	</script>

  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Ankur Handa</a></h1>
            <p class="site-description">writing my views on things I like</p>
          </div>

          <nav>
            <a href="/about">About</a>
            <a href="/">Blog</a>
            <a href="/publications">Publications</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>Different DQN variations</h1>

  <div class="entry">
    <p>Over the years, different variations of the classic DQN have appeared each with their own attempt at reducing the amount of data needed to learn <em>i.e.</em> data efficiency and increasing the overall performance racked against humans at the ATARI benchmarks. These variations are listed below.</p>

<p><strong>Classic DQN</strong></p>

<script type="math/tex; mode=display">\mathcal{L} = (R_{t+1} + \gamma_{t} \max_{a'} Q_{\bar{\theta}}  (S_{t+1}, a') - Q_{\theta}(S_{t}, A_{t}))^2</script>

<p><strong>Double DQN</strong></p>

<script type="math/tex; mode=display">\mathcal{L} = (R_{t+1} + \gamma_{t} Q_{\bar{\theta}}(S_{t+1}, \underset{a'}{\operatorname{argmax}} Q_{\theta}  (S_{t+1}, a')) - Q_{\theta}(S_{t}, A_{t}))^2</script>

<p><strong>Prioritised Replay</strong></p>

<script type="math/tex; mode=display">p_t  \propto |R_{t+1} + \gamma_{t} \max_{a'} Q_{\bar{\theta}}  (S_{t+1}, a') - Q_{\theta}(S_{t}, A_{t})|^{\omega}</script>

<p><strong>Dueling Networks</strong></p>

<script type="math/tex; mode=display">Q_{\theta}(s, a) = V_{\eta}(f_{\xi}(s)) + A_{\phi}(f_{\xi}(s), a) - \frac{\sum_{a'} A_{\phi}(f_{\xi}(s), a')}{N_{actions}}</script>

<p>where <script type="math/tex">V</script> is the value function and <script type="math/tex">A</script> is the advantage function.</p>

<p><strong>Multi-step Returns</strong></p>

<script type="math/tex; mode=display">R_{t}^{(n)} = \sum_{k=0}^{n-1} \gamma_{t}^{(k)} R_{t+k+1}</script>

<script type="math/tex; mode=display">\mathcal{L} =  (R_{t}^{(n)} + \gamma_{t}^{(n)} \max_{a'} Q_{\bar{\theta}}  (S_{t+n}, a') - Q_{\theta}(S_{t}, A_{t}))^2</script>

<p><strong>Distributional RL</strong></p>

<script type="math/tex; mode=display">z^{i} = v_{min} + (i-1) \frac{v_{max}-v_{min}}{N_{atoms}-1}</script>

<script type="math/tex; mode=display">d_{t} = (\textbf{z}, p_{\theta}(S_t, A_t))</script>

<script type="math/tex; mode=display">d^{'}_{t} = (R_{t+1} + \gamma_{t+1}\textbf{z}, p_{\bar{\theta}}(S_{t+1}, a^{*}_{t+1}))</script>

<script type="math/tex; mode=display">\mathcal{L} = D_{KL}(\Phi_{z}d^{'}_{t} || d_{t})</script>

<p>where <script type="math/tex">\Phi_{z}</script> is the projection operator as explained in the original distributional RL paper. The cross entropy <script type="math/tex">D_{KL}</script> is minimised here instead of <script type="math/tex">L_{2}^{2}</script> loss function as in classic DQN.</p>

<p>Important to remember that <script type="math/tex">\gamma</script> is usually fixed in these algorithms but it can be learnt however for each different time-step. For a fixed gamma the time-horizon can be computed as</p>

<script type="math/tex; mode=display">1 + \gamma + \gamma^2 + \gamma^3 + ... = \frac{1}{1-\gamma}</script>

<p>Therefore, the effective time-horizon for <script type="math/tex">\gamma=0.99</script> is 100 time-steps.</p>

  </div>

  <div class="date">
    Written on September 10, 2017
  </div>

  
</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          












        </footer>
      </div>
    </div>

    

  </body>
</html>
