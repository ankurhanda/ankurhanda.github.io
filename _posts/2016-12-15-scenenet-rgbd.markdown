---
layout: post
title:  "SceneNet RGB-D: 5M Photorealistic Images of Synthetic Indoor Trajectories with Ground Truth"
date:   2016-12-15 22:22:59 +00:00
image: /images/SceneNetRGBD.png
categories: research
author: "Ankur Handa"
authors: "John McCormac, <strong>Ankur Handa</strong>, Stefan Leutenegger, Andrew J. Davison"
venue: "arxiv"
arxiv: https://arxiv.org/abs/1612.05079
---
We introduce SceneNet RGB-D, expanding the previous work of SceneNet to enable large scale photorealistic rendering of indoor scene trajectories. It provides pixel-perfect ground truth for scene understanding problems such as semantic segmentation, instance segmentation, and object detection, and also for geometric computer vision problems such as optical flow, depth estimation, camera pose estimation, and 3D reconstruction. Random sampling permits virtually unlimited scene configurations, and here we provide a set of 5M rendered RGB-D images from over 15K trajectories in synthetic layouts with random but physically simulated object poses. 
